# ProjectPlan.md

## Title
**Analyzing Musical and Lyrical Evolution of Popular Songs (1921–2020)**

## Authors
Aayan Verma (aayanv2) & Tarini Patel (tarinip2)

---

The purpose of our project is to investigate how the musical and lyrical characteristics of popular songs evolved over time with the help of two large-scale datasets found on Kaggle. The first is the **Spotify Dataset 1921–2020 (600k+ Tracks)**, and the other is the **960K Spotify Songs with Attributes and Lyrics**. The features of both datasets combined will allow us to explore the relationship between emotion, sound, and popularity across different genres and years. Additionally, our broader goal is to identify measurable trends in music evolution to determine whether certain lyrical or audible features are good predictors of a song’s success. In our project, we will demonstrate complete data lifecycle management while maintaining ethical and transparent practices to achieve our goal.

Our project is structured around four key research questions: **(1)** Which musical and lyrical attributes correlate most strongly with popularity? **(2)** How have lyrical sentiments and topics changed over time? **(3)** Has the predictive power of lyrics versus audio features shifted across decades? **(4)** Can a model trained on these attributes effectively estimate a song’s popularity? These questions will guide our project’s data integration, modeling, and interpretation phases. As the analysis progresses, we expect to refine these questions and make them more specific.

To tackle the project, our team consists of two members: **Aayan Verma (aayanv2)** and **Tarini Patel (tarinip2)**. To ensure equal collaboration, we will split the work evenly. Aayan will act as the **data engineer**, responsible for data ingestion, schema design, and workflow automation. Tarini will act as the **data analyst**, focusing on sentiment analysis, exploratory data analysis, and data visualization. Both of us will contribute equally to the ethical review, metadata documentation, and reproducibility verification. We will use **GitHub** for version control and project updates, where our milestones and commits correspond to major developments.

The project relies on two main datasets. The **Spotify 1921–2020 dataset** provides a variety of quantitative information including track ID, artist, album, year, and popularity. It captures both structural and emotional dimensions of songs, allowing for in-depth sentiment and trend analysis. The **Spotify Songs with Attributes and Lyrics** dataset complements the first by adding textual data in the form of song lyrics. Together, these two datasets represent two distinct data modalities — numerical and textual — enabling cross-modal analysis of musical and linguistic expressions. Integration will primarily rely on Spotify track IDs, while missing IDs will be handled through various techniques. Tools such as **Pandas** and possibly **SQL** will support integration, with all mapping operations logged for traceability. The resulting unified dataset will link each song’s musical features with derived sentiment and thematic data.

Since song lyrics are protected by copyright, raw text cannot be redistributed or stored in our repository. Instead, we will compute and retain only **derived features** — such as sentiment, emotional tone, and word frequency — ensuring compliance with intellectual property law. Ethical handling extends to attribution, citation of sources, and respect for dataset licensing terms. No personal or identifying information is included in either dataset, minimizing privacy risks.

We expect the project to follow a complete **data lifecycle model** consisting of acquisition, storage, integration, analysis, documentation, and archiving. Our repository will be organized into logical directories, separating raw and processed data, with analysis notebooks and outputs stored separately. Automation will be achieved through a **reproducible pipeline**, allowing the entire process — from data acquisition to visualization — to be rerun with a single command. This ensures transparency, consistency, and reproducibility throughout.

A key component of the project will be **data quality assessment and cleaning**. We plan to identify missing values, inconsistencies, and invalid entries, ensuring they are addressed appropriately. Duplicates will be removed, data types standardized, and missing numeric features imputed. For textual data, we will remove punctuation, capitalization, and stop words to improve interpretability. Data quality will be evaluated based on completeness, accuracy, and validity, summarized in a profiling report. These steps will ensure that all downstream analyses are based on reliable and interpretable data.

Once cleaned, we will begin **exploratory data analysis (EDA)**. We will examine relationships between lyrical sentiment, acoustic attributes, and popularity using both correlation and regression techniques. Temporal analyses will reveal trends in tempo and emotional tone. Predictive modeling using **scikit-learn** will help estimate popularity based on combined attributes. Emphasis will be placed on **model interpretability** over complexity, aligning with our goal of producing actionable insights into musical evolution. Visualization libraries such as **matplotlib** and **seaborn** will help communicate findings clearly.

Our timeline is divided into four main stages. In **weeks 1–2**, we will inspect both datasets, verifying schema, integrity, and identifying necessary cleaning. **Weeks 3–4** will focus on integration and lyrical preprocessing. By **week 5**, data profiling and cleaning will be complete, producing an integrated dataset and quality report. **Weeks 6–7** will involve analysis, modeling, and visualization, followed by a final week dedicated to documentation, reproducibility testing, and repository organization. Each milestone will be committed and tagged on GitHub to demonstrate consistent progress.

Reproducibility and transparency are core priorities. All dependencies will be listed in a `requirements.txt` file, and each script will include comments, logging, and usage instructions. A detailed `README.md` will document the workflow, and provenance will be tracked through commit histories and metadata files. Automated logs will ensure that every data transformation is traceable.

While we have a detailed plan, potential challenges remain. These include licensing restrictions on lyric data, high processing requirements for nearly one million songs, and time management across multiple project phases. Our strategies involve focusing on derived features, batching large data processes, and clear division of responsibilities to maintain efficiency.

The anticipated results will include a **cleaned and integrated dataset** combining musical and lyrical characteristics, a **data quality assessment**, and an **analytical report** with visualizations and model interpretations. The final repository will include all code, metadata, and documentation to reproduce the workflow. We expect to identify measurable trends such as increased tempo, lyrical sentiment fluctuations, and changing themes in popular music reflecting broader cultural shifts. Beyond these findings, the project’s value lies in upholding the **FAIR principles** — ensuring data is findable, accessible, interoperable, and reusable — and modeling responsible, transparent data stewardship.

In summary, this project combines two complementary music datasets to explore how the structure and sentiment of songs relate to popularity and cultural trends over time. It will encompass all stages of the data lifecycle — acquisition, cleaning, integration, analysis, and documentation — while adhering to ethical and legal standards. The final deliverable will be a reproducible repository containing code, metadata, and outputs, offering both meaningful insights into music evolution and a framework for best practices in data curation.
